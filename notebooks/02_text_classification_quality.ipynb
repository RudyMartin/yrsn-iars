{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Notebook 2: Text Classification Quality for Support Tickets\n",
    "\n",
    "**Objective**: Handle text-specific quality issues in IT support ticket routing:\n",
    "- Detect toxic/PII/informal content\n",
    "- Identify ambiguous or verbose tickets\n",
    "- Route tickets correctly despite quality issues\n",
    "\n",
    "---\n",
    "\n",
    "## Flow Diagram\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph Input[\"ðŸ“¥ Support Tickets\"]\n",
    "        A[Ticket Text]\n",
    "        B[Category Labels]\n",
    "        C[Priority]\n",
    "    end\n",
    "\n",
    "    subgraph TextQuality[\"ðŸ“ Text Quality Analysis\"]\n",
    "        D[Toxic Detection]\n",
    "        E[PII Detection]\n",
    "        F[Language Quality]\n",
    "        G[Informality Score]\n",
    "    end\n",
    "\n",
    "    subgraph Cleanlab[\"ðŸ§¹ Cleanlab Analysis\"]\n",
    "        H[get_label_quality_scores]\n",
    "        I[find_label_issues]\n",
    "        J[get_confidence_weighted_entropy]\n",
    "    end\n",
    "\n",
    "    subgraph YRSN[\"ðŸŽ¯ YRSN Mapping\"]\n",
    "        K{Text Issue Type?}\n",
    "        L[Toxic/PII â†’ N High]\n",
    "        M[Informal â†’ S Moderate]\n",
    "        N[Verbose â†’ S High]\n",
    "        O[Clean â†’ R High]\n",
    "    end\n",
    "\n",
    "    subgraph Routing[\"ðŸš¦ Temperature Routing\"]\n",
    "        P[Compute Ï„ = 1/Î±]\n",
    "        Q{Ï„ Level?}\n",
    "        R[ðŸŸ¢ GREEN: Auto-route]\n",
    "        S[ðŸŸ¡ YELLOW: Summarize first]\n",
    "        T[ðŸ”´ RED: Human review]\n",
    "    end\n",
    "\n",
    "    A --> D\n",
    "    A --> E\n",
    "    A --> F\n",
    "    A --> G\n",
    "    B --> H\n",
    "    D --> K\n",
    "    E --> K\n",
    "    F --> K\n",
    "    G --> K\n",
    "    H --> K\n",
    "    I --> K\n",
    "    J --> K\n",
    "    K --> L\n",
    "    K --> M\n",
    "    K --> N\n",
    "    K --> O\n",
    "    L --> P\n",
    "    M --> P\n",
    "    N --> P\n",
    "    O --> P\n",
    "    P --> Q\n",
    "    Q -->|Low Ï„| R\n",
    "    Q -->|Mid Ï„| S\n",
    "    Q -->|High Ï„| T\n",
    "\n",
    "    style TextQuality fill:#fff3e0\n",
    "    style Cleanlab fill:#e1f5fe\n",
    "    style YRSN fill:#e8f5e9\n",
    "    style Routing fill:#fce4ec\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Collapse Type Focus**: DISTRACTION (verbose/unfocused tickets)\n",
    "\n",
    "**Difficulty**: â­ Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install cleanlab sentence-transformers scikit-learn pandas boto3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from cleanlab.filter import find_label_issues\n",
    "from cleanlab.rank import get_label_quality_scores\n",
    "\n",
    "# Import YRSN adapter\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from yrsn_iars.adapters.cleanlab_adapter import CleanlabAdapter, YRSNResult\n",
    "\n",
    "print(\"Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Load Support Ticket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic support ticket data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "categories = ['hardware', 'software', 'network', 'access', 'other']\n",
    "\n",
    "# Templates for different quality levels\n",
    "clean_templates = [\n",
    "    \"My laptop screen is not displaying properly. Error code: {code}. Please advise.\",\n",
    "    \"Request access to {system}. Manager approval attached. User ID: {user}.\",\n",
    "    \"Network connectivity issue in building {building}. Affecting {n} users.\",\n",
    "]\n",
    "\n",
    "informal_templates = [\n",
    "    \"hey my laptop broke lol can u fix it asap???\",\n",
    "    \"URGENT!!!! NEED ACCESS NOW!!!! been waiting forever!!!\",\n",
    "    \"wifi is super slow today ugh so annoying\",\n",
    "]\n",
    "\n",
    "verbose_templates = [\n",
    "    \"So yesterday I was working on my laptop and everything was fine but then today when I came in and turned it on the screen started flickering and I tried restarting it multiple times but it keeps happening and I really need to finish my project because the deadline is tomorrow and I don't know what to do please help me as soon as possible thank you so much.\",\n",
    "]\n",
    "\n",
    "# Generate tickets\n",
    "tickets = []\n",
    "for i in range(n_samples):\n",
    "    quality_type = np.random.choice(['clean', 'informal', 'verbose'], p=[0.6, 0.25, 0.15])\n",
    "    \n",
    "    if quality_type == 'clean':\n",
    "        text = np.random.choice(clean_templates).format(\n",
    "            code=np.random.randint(1000, 9999),\n",
    "            system=np.random.choice(['SAP', 'Salesforce', 'SharePoint']),\n",
    "            user=f'user_{np.random.randint(100, 999)}',\n",
    "            building=np.random.choice(['A', 'B', 'C']),\n",
    "            n=np.random.randint(5, 50)\n",
    "        )\n",
    "    elif quality_type == 'informal':\n",
    "        text = np.random.choice(informal_templates)\n",
    "    else:\n",
    "        text = np.random.choice(verbose_templates)\n",
    "    \n",
    "    tickets.append({\n",
    "        'ticket_id': f'TKT-{i:05d}',\n",
    "        'text': text,\n",
    "        'category': np.random.choice(categories),\n",
    "        'priority': np.random.choice(['low', 'medium', 'high']),\n",
    "        'quality_type': quality_type  # Ground truth for evaluation\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(tickets)\n",
    "\n",
    "# Inject some label noise\n",
    "noise_indices = np.random.choice(n_samples, size=int(n_samples * 0.08), replace=False)\n",
    "for idx in noise_indices:\n",
    "    df.loc[idx, 'category'] = np.random.choice(categories)\n",
    "\n",
    "print(f\"Generated {len(df)} support tickets\")\n",
    "print(f\"\\nCategory distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nQuality type distribution:\")\n",
    "print(df['quality_type'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Text Quality Analysis\n",
    "\n",
    "Detect text-specific quality issues that affect YRSN components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_text_quality_scores(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compute text quality signals for YRSN mapping.\n",
    "    \n",
    "    In production, use AWS Comprehend or dedicated models.\n",
    "    This is a simple heuristic version.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Informality indicators\n",
    "    informal_patterns = ['lol', 'asap', '!!!', 'plz', 'u ', 'pls', 'omg', 'brb']\n",
    "    informality = sum(1 for p in informal_patterns if p in text_lower) / len(informal_patterns)\n",
    "    \n",
    "    # Verbosity (excessive length)\n",
    "    word_count = len(text.split())\n",
    "    verbosity = min(1.0, max(0, (word_count - 50) / 100))  # Scale 50-150 words\n",
    "    \n",
    "    # ALL CAPS detection (urgency/frustration)\n",
    "    caps_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
    "    \n",
    "    # PII patterns (very basic)\n",
    "    pii_patterns = ['ssn', 'social security', 'password', 'credit card']\n",
    "    has_pii = any(p in text_lower for p in pii_patterns)\n",
    "    \n",
    "    # Toxic patterns (very basic, use proper model in production)\n",
    "    toxic_patterns = ['stupid', 'idiot', 'hate', 'worst']\n",
    "    toxicity = any(p in text_lower for p in toxic_patterns)\n",
    "    \n",
    "    return {\n",
    "        'informality': informality,\n",
    "        'verbosity': verbosity,\n",
    "        'caps_ratio': caps_ratio,\n",
    "        'has_pii': has_pii,\n",
    "        'toxicity': toxicity,\n",
    "        'word_count': word_count\n",
    "    }\n",
    "\n",
    "# Apply to all tickets\n",
    "quality_scores = df['text'].apply(compute_text_quality_scores).apply(pd.Series)\n",
    "df = pd.concat([df, quality_scores], axis=1)\n",
    "\n",
    "print(\"Text Quality Statistics:\")\n",
    "print(quality_scores.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings and Cleanlab Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentence transformer\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = encoder.encode(df['text'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df['category'])\n",
    "\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier and get cross-validated predictions\n",
    "clf = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "\n",
    "print(\"Getting cross-validated predictions...\")\n",
    "pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    embeddings,\n",
    "    labels,\n",
    "    cv=5,\n",
    "    method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Get Cleanlab scores\n",
    "label_quality = get_label_quality_scores(labels, pred_probs)\n",
    "df['label_quality'] = label_quality\n",
    "\n",
    "label_issues = find_label_issues(labels, pred_probs)\n",
    "df['is_label_issue'] = label_issues\n",
    "\n",
    "print(f\"Found {label_issues.sum()} label issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. YRSN Decomposition with Text Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YRSN adapter\n",
    "adapter = CleanlabAdapter()\n",
    "\n",
    "# Compute YRSN for each ticket\n",
    "def compute_ticket_yrsn(row):\n",
    "    \"\"\"Combine label quality with text quality for YRSN.\"\"\"\n",
    "    \n",
    "    # Get base YRSN from Cleanlab signals\n",
    "    pred_prob = pred_probs[row.name]\n",
    "    entropy = -np.sum(pred_prob * np.log(pred_prob + 1e-10))\n",
    "    max_entropy = np.log(len(pred_prob))\n",
    "    normalized_entropy = entropy / max_entropy\n",
    "    \n",
    "    sorted_probs = np.sort(pred_prob)\n",
    "    margin = sorted_probs[-1] - sorted_probs[-2]\n",
    "    normalized_margin = (margin + 1) / 2\n",
    "    \n",
    "    base_yrsn = adapter.example_to_yrsn(\n",
    "        label_quality=row['label_quality'],\n",
    "        normalized_margin=normalized_margin,\n",
    "        normalized_entropy=normalized_entropy\n",
    "    )\n",
    "    \n",
    "    # Apply text quality adjustments\n",
    "    text_yrsn = adapter.text_quality_to_yrsn(\n",
    "        toxic_score=1.0 if row['toxicity'] else 0.0,\n",
    "        pii_score=1.0 if row['has_pii'] else 0.0,\n",
    "        informal_score=row['informality']\n",
    "    )\n",
    "    \n",
    "    # Combine (weighted average)\n",
    "    combined_R = 0.6 * base_yrsn.R + 0.4 * text_yrsn.R\n",
    "    combined_S = 0.6 * base_yrsn.S + 0.4 * text_yrsn.S + 0.2 * row['verbosity']  # Verbosity â†’ S\n",
    "    combined_N = 0.6 * base_yrsn.N + 0.4 * text_yrsn.N\n",
    "    \n",
    "    # Normalize\n",
    "    total = combined_R + combined_S + combined_N\n",
    "    return YRSNResult(R=combined_R/total, S=combined_S/total, N=combined_N/total)\n",
    "\n",
    "# Apply YRSN computation\n",
    "yrsn_results = df.apply(compute_ticket_yrsn, axis=1)\n",
    "df['R'] = [y.R for y in yrsn_results]\n",
    "df['S'] = [y.S for y in yrsn_results]\n",
    "df['N'] = [y.N for y in yrsn_results]\n",
    "df['collapse_type'] = [y.collapse_type.value for y in yrsn_results]\n",
    "\n",
    "print(\"YRSN Statistics:\")\n",
    "print(df[['R', 'S', 'N']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Temperature-Based Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yrsn_iars.adapters.temperature import compute_temperature, TemperatureMode\n",
    "\n",
    "# Compute temperature for each ticket\n",
    "df['temperature'] = df['R'].apply(lambda r: compute_temperature(r))\n",
    "\n",
    "# Determine routing stream\n",
    "def determine_stream(row):\n",
    "    tau = row['temperature']\n",
    "    R = row['R']\n",
    "    N = row['N']\n",
    "    \n",
    "    # Collapse check\n",
    "    if row['collapse_type'] in ['poisoning', 'confusion']:\n",
    "        return 'red'\n",
    "    \n",
    "    # Temperature-adjusted routing\n",
    "    if tau < 1.2 and R > 0.6 and N < 0.2:\n",
    "        return 'green'\n",
    "    elif tau < 2.0 and R > 0.4:\n",
    "        return 'yellow'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "df['stream'] = df.apply(determine_stream, axis=1)\n",
    "\n",
    "print(\"Routing Distribution:\")\n",
    "print(df['stream'].value_counts())\n",
    "print(f\"\\nAutomation rate: {100 * (df['stream'] == 'green').mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Analyze Routing by Text Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulate quality type with routing stream\n",
    "routing_by_quality = pd.crosstab(\n",
    "    df['quality_type'],\n",
    "    df['stream'],\n",
    "    normalize='index'\n",
    ").round(3) * 100\n",
    "\n",
    "print(\"Routing Distribution by Text Quality Type (%):\")\n",
    "print(routing_by_quality)\n",
    "\n",
    "# Average YRSN by quality type\n",
    "print(\"\\nAverage YRSN by Quality Type:\")\n",
    "print(df.groupby('quality_type')[['R', 'S', 'N', 'temperature']].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8. Examine DISTRACTION Cases (High S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tickets with high S (superfluous/verbose)\n",
    "distraction_cases = df[df['collapse_type'] == 'distraction'].nlargest(10, 'S')\n",
    "\n",
    "print(\"Top 10 DISTRACTION Cases (High S):\")\n",
    "print(\"=\"*80)\n",
    "for _, row in distraction_cases.iterrows():\n",
    "    print(f\"\\n[{row['ticket_id']}] R={row['R']:.2f}, S={row['S']:.2f}, N={row['N']:.2f}\")\n",
    "    print(f\"Stream: {row['stream'].upper()}, Ï„={row['temperature']:.2f}\")\n",
    "    print(f\"Text: {row['text'][:150]}...\" if len(row['text']) > 150 else f\"Text: {row['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for next notebook\n",
    "output_cols = ['ticket_id', 'text', 'category', 'priority', \n",
    "               'R', 'S', 'N', 'collapse_type', 'temperature', 'stream',\n",
    "               'label_quality', 'informality', 'verbosity']\n",
    "\n",
    "df[output_cols].to_csv('ticket_yrsn_results.csv', index=False)\n",
    "print(f\"Saved {len(df)} tickets with YRSN analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we:\n",
    "1. Loaded support ticket data with various text quality issues\n",
    "2. Computed text-specific quality signals (informality, verbosity, toxicity)\n",
    "3. Combined Cleanlab label quality with text quality for YRSN decomposition\n",
    "4. Applied temperature-based routing (Ï„ = 1/Î±)\n",
    "5. Analyzed routing patterns by text quality type\n",
    "6. Identified DISTRACTION collapse cases (high S)\n",
    "\n",
    "**Key Insight**: Verbose/informal text increases S (superfluous), which raises temperature and routes to yellow/red for human summarization before processing.\n",
    "\n",
    "**Next**: Notebook 3 - Multi-Annotator Consensus for Committee Decisions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
